{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34104fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import re\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import ElementNotInteractableException, NoSuchElementException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12d937",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e3ca1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b9bed",
   "metadata": {},
   "source": [
    "### 1 Scrape the details of most viewed videos on YouTube from Wikipedia. \n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos \n",
    "\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb4794",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_1=[]\n",
    "name_1=[]\n",
    "artist_1=[]\n",
    "date_1=[]\n",
    "views_1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7aab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "table = driver.find_element(By.XPATH,'''//table[@class=\"wikitable sortable jquery-tablesorter\"]''')\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "for row in rows:\n",
    "    data = row.find_elements(By.TAG_NAME, 'td')\n",
    "    #there are 2 rows where no of columns are not same then others thats why we \n",
    "    #are using if condition\n",
    "    if len(data) > 0:\n",
    "        rank_1.append(data[0].text)\n",
    "        name_1.append(data[1].text)\n",
    "        artist_1.append(data[2].text)\n",
    "        date_1.append(data[4].text)\n",
    "        views_1.append(data[3].text)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame({\"Rank\":rank_1, \"Name\":name_1, \"Artist\":artist_1, \"Upload Date\":date_1, \"Views\":views_1})\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68434d3a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73c903",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e8fa8c",
   "metadata": {},
   "source": [
    "### 2 Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1 ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_2=[]\n",
    "series_2=[]\n",
    "place_2=[]\n",
    "date_2=[]\n",
    "time_2=[]\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "driver.maximize_window()\n",
    "try:\n",
    "    WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'//a[@class=\"moreMatchesLink\"]')))\n",
    "except:\n",
    "    driver.quit()\n",
    "else:\n",
    "    time.sleep(5)\n",
    "    driver.find_element(By.TAG_NAME,'body').send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(2)\n",
    "    driver.find_element(By.CSS_SELECTOR,'.moreMatchesLink').click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element(By.XPATH,'//button[@class=\"cookie__accept btn btn-primary\"]').click()\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(3)\n",
    "            driver.find_element(By.XPATH,'//button[@class=\"match-btn btn-red d-flex align-items-center justify-content-center mx-auto mt-3\"]').click()\n",
    "        except NoSuchElementException as e:\n",
    "            print(e)\n",
    "            break\n",
    "            \n",
    "#fetching data\n",
    "datas = driver.find_elements(By.XPATH,'//div[@class=\"col-lg-4 col-md-6 col-sm-12 ng-scope\"]')\n",
    "driver.quit()\n",
    "for data in datas:\n",
    "    #fetching Match title\n",
    "    title = data.find_element(By.XPATH, './/span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "    title = title.text\n",
    "    title = title.replace(\" -\",\"\")\n",
    "    title_2.append(title)\n",
    "    \n",
    "    #fetching series name\n",
    "    series = data.find_element(By.XPATH,'.//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "    series_2.append(series.text)\n",
    "    \n",
    "    #fetching place location\n",
    "    place_one=\"\"\n",
    "    place_two=\"\"\n",
    "    try:\n",
    "        place_one = data.find_element(By.XPATH,'.//span[@class=\"ng-binding ng-scope\"]')\n",
    "        place_one = place_one.text\n",
    "    except NoSuchElementException as e:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        place_two = data.find_element(By.XPATH,'.//span[@class=\"ng-binding\"]')\n",
    "        place_two = place_two.text\n",
    "    except NoSuchElementException as e:\n",
    "        pass\n",
    "    \n",
    "    if len(place_one) | len(place_two)>0:\n",
    "        place = place_one + place_two\n",
    "        place_2.append(place)\n",
    "    else:\n",
    "        place = \"-\"\n",
    "        place_2.append(place)\n",
    "        \n",
    "    #fetching date\n",
    "    date = data.find_element(By.XPATH, './/div[@class=\"match-dates ng-binding\"]')\n",
    "    date_2.append(date.text)\n",
    "    \n",
    "    \n",
    "    #fetching time\n",
    "    timee = data.find_element(By.XPATH, './/div[@class=\"match-time no-margin ng-binding\"]')\n",
    "    time_2.append(timee.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame({\"Match title\":title_2, \"Series\":series_2, \"Place\":place_2, \"Date\":date_2, \"Time\":time_2})\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9432b4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee371bc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c96aa",
   "metadata": {},
   "source": [
    "### 3 Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:   \n",
    "A)Rank  \n",
    "B) State  \n",
    "C) GSDP(18-19)- at current prices  \n",
    "D) GSDP(19-20)- at current prices  \n",
    "E) Share(18-19)  \n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97290ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_3=[]\n",
    "state_3=[]\n",
    "gsdp_3_19=[]\n",
    "gsdp_3_20=[]\n",
    "share_3=[]\n",
    "gdp_3=[]\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.statisticstimes.com/\")\n",
    "driver.maximize_window()\n",
    "driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]/button').click()\n",
    "driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]').click()\n",
    "time.sleep(2)\n",
    "try:\n",
    "    driver.find_element(By.XPATH, \".//div[span[text()='Close']]\").click()\n",
    "    time.sleep(2)\n",
    "except NoSuchElementException as e:\n",
    "    pass\n",
    "time.sleep(2)\n",
    "driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "\n",
    "#fetching table and then rows\n",
    "table = driver.find_element(By.XPATH, '//table[@class=\"display dataTable\"]')\n",
    "rows = table.find_elements(By.CSS_SELECTOR, '.odd,.even')\n",
    "\n",
    "for col in rows:\n",
    "    rank_3.append(col.find_element(By.XPATH, './/td[@class=\"data1\"]').text)\n",
    "    state_3.append(col.find_element(By.XPATH, './/td[@class=\"name\"]').text)\n",
    "    gsdp_3_19.append(col.find_element(By.XPATH, './/td[@class=\"data sorting_1\"]').text)\n",
    "    gsdp_3_20.append(col.find_element(By.XPATH, './/td[@class=\"data\"]').text)\n",
    "    share_3.append(col.find_element(By.XPATH, './/td[@class=\"data\"][2]').text)\n",
    "    gdp_3.append(col.find_element(By.XPATH, './/td[@class=\"data\"][3]').text)\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.DataFrame({\"Rank\":rank_3, \"State\":state_3, \"GSDP(18-19)- at current prices\":gsdp_3_19, \"GSDP(19-20)- at current prices\":gsdp_3_20, \"Share(18-19)\":share_3, \"GDP($ billion)\":gdp_3 })\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1a965",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c581e92",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b6a938",
   "metadata": {},
   "source": [
    "### 4 Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:  \n",
    "A) Repository title  \n",
    "B) Repository description  \n",
    "C) Contributors count  \n",
    "D) Language used  \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_4=[]\n",
    "desc_4=[]\n",
    "contri_count_4=[]\n",
    "lang_4=[]\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://github.com/\")\n",
    "driver.maximize_window()\n",
    "driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button').click()\n",
    "driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a').click()\n",
    "\n",
    "time.sleep(5)\n",
    "title = driver.find_elements(By.XPATH, '//h2[@class=\"h3 lh-condensed\"]')\n",
    "for i in title:\n",
    "    title_4.append(i.text)\n",
    "    \n",
    "desc = driver.find_elements(By.XPATH, '//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in desc:\n",
    "    desc_4.append(i.text)\n",
    "    \n",
    "cnt = driver.find_elements(By.XPATH, '//a[@class=\"Link Link--muted d-inline-block mr-3\"]')\n",
    "for i in cnt[1::2]:\n",
    "    contri_count_4.append(i.text)\n",
    "    \n",
    "rows = driver.find_elements(By.XPATH, '//article[@class=\"Box-row\"]')\n",
    "for row in rows:\n",
    "    try:\n",
    "        lang_4.append(row.find_element(By.XPATH, './/span[@class=\"d-inline-block ml-0 mr-3\"]').text)\n",
    "    except NoSuchElementException as e:\n",
    "        lang_4.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f305c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.DataFrame({\"Repository title\": title_4, \"Repository description\":desc_4, \"Contribution count\":contri_count_4, \"Language Used\":lang_4})\n",
    "df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346f94a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dca00f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc48f0",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "\n",
    "You have to find the following details:  \n",
    "A) Song name  \n",
    "B) Artist name  \n",
    "C) Last week rank  \n",
    "D) Peak rank  \n",
    "E) Weeks on board  \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_5=[]\n",
    "artist_5=[]\n",
    "last_rank_5=[]\n",
    "peak_rank_5=[]\n",
    "weeks_board_5=[]\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.billboard.com/\")\n",
    "driver.maximize_window()\n",
    "driver.find_element(By.XPATH, '/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a').click()\n",
    "driver.find_element(By.XPATH, '/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]/span/a').click()\n",
    "time.sleep(3)\n",
    "rows = driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]')\n",
    "\n",
    "for i in rows:\n",
    "    song_5.append(i.find_element(By.ID, 'title-of-a-story').text)\n",
    "    artist_5.append(i.find_element(By.XPATH,'.//li/ul/li/span').text)\n",
    "    last_rank_5.append(i.find_element(By.XPATH,'.//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]').text)\n",
    "    peak_rank_5.append(i.find_element(By.XPATH, './/li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"][2]').text)\n",
    "    weeks_board_5.append(i.find_element(By.XPATH, './/li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"][2]').text)\n",
    "    \n",
    "driver.quit()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64945835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = pd.DataFrame({\"Song Name\":song_5, \"Artist Name\":artist_5, \"Last week rank\":last_rank_5, \"Peak rank\":peak_rank_5, \"Weeks on board\":weeks_board_5})\n",
    "df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be155d6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003e7ce",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4312c",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "\n",
    "A) Book name  \n",
    "B) Author name  \n",
    "C) Volumes sold  \n",
    "D) Publisher  \n",
    "E) Genre  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "4d26c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_6=[]\n",
    "author_6=[]\n",
    "sold_6=[]\n",
    "publish_6=[]\n",
    "genre_6=[]\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "table = driver.find_element(By.XPATH, '//table[@class=\"in-article sortable\"]')\n",
    "rows = driver.find_elements(By.XPATH, './/tbody/tr')\n",
    "for row in rows:\n",
    "    book=row.find_element(By.XPATH, './/td[2]')\n",
    "    book_6.append(book.text)\n",
    "    \n",
    "    author=row.find_element(By.XPATH, './/td[3]')\n",
    "    author_6.append(author.text)\n",
    "    \n",
    "    sold_=row.find_element(By.XPATH, './/td[4]')\n",
    "    sold_6.append(sold_.text)\n",
    "    \n",
    "    publ=row.find_element(By.XPATH, './/td[5]')\n",
    "    publish_6.append(publ.text)\n",
    "    \n",
    "    genre=row.find_element(By.XPATH, './/td[6]')\n",
    "    genre_6.append(genre.text)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "494b0985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_6 = pd.DataFrame({\"Book Name\":book_6, \"Author Name\":author_6, \"Volumes Sold\":sold_6, \"Publisher\":publish_6, \"Genre\":genre_6})\n",
    "df_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd7d6e0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51285d8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ef5a1b",
   "metadata": {},
   "source": [
    "### 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ \n",
    "\n",
    "You have to find the following details:  \n",
    "A) Name  \n",
    "B) Year span  \n",
    "C) Genre  \n",
    "D) Run time  \n",
    "E) Ratings  \n",
    "F) Votes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_7=[]\n",
    "year_7=[]\n",
    "genre_7=[]\n",
    "run_7=[]\n",
    "rating_7=[]\n",
    "votes_7=[]\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "rows = driver.find_elements(By.XPATH, '//div[@class=\"lister-item mode-detail\"]')\n",
    "for row in rows:\n",
    "    name = row.find_element(By.XPATH, './/div/h3/a')\n",
    "    name_7.append(name.text)\n",
    "    \n",
    "    year = row.find_element(By.XPATH, './/div/h3/span[2]')\n",
    "    year_7.append(year.text)\n",
    "    \n",
    "    genre = row.find_element(By.XPATH, './/span[@class=\"genre\"]')\n",
    "    genre_7.append(genre.text)\n",
    "    \n",
    "    runtime = row.find_element(By.XPATH, './/span[@class=\"runtime\"]')\n",
    "    run_7.append(runtime.text)\n",
    "    \n",
    "    rate = row.find_element(By.XPATH, './/div[@class=\"ipl-rating-star small\"]')\n",
    "    rating_7.append(rate.text)\n",
    "    \n",
    "    vote = row.find_element(By.XPATH, './/span[@name=\"nv\"]')\n",
    "    votes_7.append(vote.text) \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7 = pd.DataFrame({\"Name\": name_7, \"Year span\": year_7, \"Genre\":genre_7, \"Run Time\":run_7, \"Ratings\": rating_7, \"Votes\": votes_7})\n",
    "df_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a08352",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff34c092",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f9f6cf",
   "metadata": {},
   "source": [
    "### 8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:  \n",
    "A) Dataset name  \n",
    "B) Data type  \n",
    "C) Task  \n",
    "D) Attribute type  \n",
    "E) No of instances  \n",
    "F) No of attribute  \n",
    "G) Year  \n",
    "Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b984507",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_8=[]\n",
    "type_8=[]\n",
    "task_8=[]\n",
    "att_type_8=[]\n",
    "inst_8=[]\n",
    "att_no_8=[]\n",
    "year_8=[]\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]').click()\n",
    "time.sleep(1)\n",
    "try:\n",
    "    driver.find_element(By.XPATH, '//button[@class=\"btn-primary btn-sm btn m-1\"]').click()\n",
    "    time.sleep(1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, '/html/body').send_keys(Keys.PAGE_UP)\n",
    "    driver.find_element(By.XPATH, '/html/body').send_keys(Keys.PAGE_UP)\n",
    "    time.sleep(3)\n",
    "    expands = driver.find_elements(By.XPATH, '//p[@class=\"truncate\"]')\n",
    "    for expand in expands:\n",
    "        time.sleep(0.5)\n",
    "        try:\n",
    "            expand.click()\n",
    "        except ElementClickInterceptedException as e:\n",
    "            driver.execute_script(\"window.scrollBy(0,100);\")\n",
    "            expand.click()\n",
    "    time.sleep(4)\n",
    "    rows = driver.find_elements(By.XPATH, '//div[@class=\"rounded-box bg-base-100\"]')\n",
    "    for row in rows:\n",
    "        name = row.find_element(By.XPATH, './/h2[@class=\"truncate text-primary\"]')\n",
    "        name_8.append(name.text)\n",
    "\n",
    "\n",
    "        type_ = row.find_element(By.XPATH, './/div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]')\n",
    "        if len(type_.text)>0:\n",
    "            type_8.append(type_.text)\n",
    "        else:\n",
    "            type_8.append(\"-\")\n",
    "\n",
    "\n",
    "        task_ = row.find_element(By.XPATH, './/div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]')\n",
    "        if len(task_.text)>0:\n",
    "            task_8.append(task_.text)\n",
    "        else:\n",
    "            task_8.append(\"-\")\n",
    "\n",
    "\n",
    "        att_type_ = row.find_element(By.XPATH, './/tbody[@class=\"border\"]/tr/td[2]')\n",
    "        att_type_8.append(att_type_.text)\n",
    "\n",
    "\n",
    "        inst_ = row.find_element(By.XPATH, './/div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]')\n",
    "        if len(inst_.text)>0:\n",
    "            inst_8.append(inst_.text)\n",
    "        else:\n",
    "            inst_8.append(\"-\")\n",
    "\n",
    "\n",
    "        att_ = row.find_element(By.XPATH, './/div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]')\n",
    "        if len(att_.text)>0:\n",
    "            att_no_8.append(att_.text)\n",
    "        else:\n",
    "            att_no_8.append(\"-\")\n",
    "\n",
    "\n",
    "        year_ = row.find_element(By.XPATH, './/tbody[@class=\"border\"]/tr/td[3]')\n",
    "        year_8.append(year_.text)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        driver.find_element(By.XPATH, '/html/body').send_keys(Keys.PAGE_DOWN)\n",
    "        driver.find_element(By.XPATH, '/html/body').send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(1)\n",
    "        driver.find_element(By.XPATH, '//button[@class=\"btn-primary btn-sm btn\"][2]').click()\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8 = pd.DataFrame({\"Dataset name\": name_8, \"Data type\": type_8, \"Task\":task_8, \"Attribute Type\":att_type_8, \"No of Instances\":inst_8, \"No of Attribute\":att_no_8, \"Year\": year_8})\n",
    "df_8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
